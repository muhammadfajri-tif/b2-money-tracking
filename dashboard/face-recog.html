<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Face Recognition</title>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, shrink-to-fit=yes" />
    <link rel="shortcut icon" href="../favicon.ico" type="image/x-icon" />
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1/dist/face-api.js"></script>

    <script type="module">
      const modelPath =
        "https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/"; // CDN model path
      // "../models/"; // local model path
      const minScore = 0.2;
      const maxResults = 5;
      let optionsSSDMobileNet;
      function str(json) {
        let text = '<font color="lightblue">';
        text += json
          ? JSON.stringify(json)
              .replace(/{|}|"|\[|\]/g, "")
              .replace(/,/g, ", ")
          : "";
        text += "</font>";
        return text;
      }
      function log(...txt) {
        console.log(...txt);
        const div = document.getElementById("log");
        if (div) div.innerHTML += `<br>${txt}`;
      }
      function drawFaces(canvas, data, fps, smileTime) {
        const ctx = canvas.getContext("2d", { willReadFrequently: true });
        if (!ctx) return;
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        // draw fps
        ctx.font = 'small-caps 20px "Segoe UI"';
        ctx.fillStyle = "white";
        ctx.fillText(`FPS: ${fps}`, 10, 25);

        // draw smile time
        const overlayPadding = 10;
        const text =
          smileTime !== 0
            ? `Hold your smile until 5 seconds, your time: ${smileTime} seconds`
            : "Please Smile To Login :)";
        const textWidth = ctx.measureText(text).width; // Calculate the width of the text
        const overlayWidth = textWidth + 1 * overlayPadding; // Calculate the width of the overlay rectangle
        const overlayHeight = 50; // Height of the overlay rectangle
        const overlayX = (canvas.width - overlayWidth) / 2; // X coordinate to center the overlay
        const overlayY = 10; // Y coordinate of the overlay
        ctx.font = 'bold 16px "Segoe UI"';
        ctx.fillStyle = "rgba(0, 0, 0, 0.7)";
        ctx.fillRect(overlayX, overlayY, overlayWidth, overlayHeight); // Adjust the position and size of the overlay rectangle
        ctx.fillStyle = "white";
        const textX = overlayX + (overlayWidth - textWidth + 30) / 2; // X coordinate to center the text within the overlay
        ctx.fillText(text, textX, overlayY + 30); // Adjust the position of the text

        // draw overlay for Having problem with cam? Click Here
        ctx.fillStyle = "rgba(0, 0, 0, 0.7)";
        // change overlay position to right top corner
        const overlayWidth2 = 390; // Width of the overlay rectangle
        const overlayX2 = canvas.width - overlayWidth2 - 50; // X coordinate to right align the overlay
        const overlayY2 = 10; // Y coordinate of the overlay
        ctx.fillRect(overlayX2, overlayY2, overlayWidth2, 60); // Adjust the position and size of the overlay rectangle

        // Draw Having problem with cam? Click Here
        ctx.font = 'bold 20px "Segoe UI"'; // Adjust the font size and style
        ctx.fillStyle = "white";
        ctx.fillText(
          "Having problem with cam?",
          overlayX2 + 10,
          overlayY2 + 40
        ); // Adjust the position of the text
        ctx.fillStyle = "red";
        ctx.fillText("Click Here", overlayX2 + 280, overlayY2 + 40); // Adjust the position of the text

        // draw overlay for emotional state
        ctx.fillStyle = "rgba(0, 0, 0, 0.7)";
        ctx.fillRect(10, canvas.height - 70, 230, 50); // Adjust the size of the overlay rectangle

        // Draw emotional state
        ctx.font = 'bold 20px "Segoe UI"'; // Adjust the font size and style
        ctx.fillStyle = "white";
        ctx.fillText("Emotion: ", 20, canvas.height - 35); // Adjust the position of the text

        for (const person of data) {
          // draw box around each face
          ctx.lineWidth = 3;
          ctx.strokeStyle = "deepskyblue";
          ctx.fillStyle = "deepskyblue";
          ctx.globalAlpha = 0.6;
          ctx.beginPath();
          ctx.rect(
            person.detection.box.x,
            person.detection.box.y,
            person.detection.box.width,
            person.detection.box.height
          );
          ctx.stroke();
          ctx.globalAlpha = 1;
          // draw text labels
          const expression = Object.entries(person.expressions).sort(
            (a, b) => b[1] - a[1]
          );
          ctx.fillStyle = "black";
          ctx.fillText(
            `gender: ${Math.round(100 * person.genderProbability)}% ${
              person.gender
            }`,
            person.detection.box.x,
            person.detection.box.y - 59
          );
          ctx.fillText(
            `expression: ${Math.round(100 * expression[0][1])}% ${
              expression[0][0]
            }`,
            person.detection.box.x,
            person.detection.box.y - 41
          );
          ctx.fillText(
            `age: ${Math.round(person.age)} years`,
            person.detection.box.x,
            person.detection.box.y - 23
          );
          ctx.fillText(
            `roll:${person.angle.roll}° pitch:${person.angle.pitch}° yaw:${person.angle.yaw}°`,
            person.detection.box.x,
            person.detection.box.y - 5
          );
          ctx.fillStyle = "lightblue";
          ctx.fillText(
            `gender: ${Math.round(100 * person.genderProbability)}% ${
              person.gender
            }`,
            person.detection.box.x,
            person.detection.box.y - 60
          );
          ctx.fillText(
            `expression: ${Math.round(100 * expression[0][1])}% ${
              expression[0][0]
            }`,
            person.detection.box.x,
            person.detection.box.y - 42
          );
          ctx.fillText(
            `age: ${Math.round(person.age)} years`,
            person.detection.box.x,
            person.detection.box.y - 24
          );
          ctx.fillText(
            `roll:${person.angle.roll}° pitch:${person.angle.pitch}° yaw:${person.angle.yaw}°`,
            person.detection.box.x,
            person.detection.box.y - 6
          );
          // draw face points for each face
          ctx.globalAlpha = 0.8;
          ctx.fillStyle = "lightblue";
          const pointSize = 2;
          for (let i = 0; i < person.landmarks.positions.length; i++) {
            ctx.beginPath();
            ctx.arc(
              person.landmarks.positions[i].x,
              person.landmarks.positions[i].y,
              pointSize,
              0,
              2 * Math.PI
            );
            ctx.fill();
          }

          // Determine emotional state
          let emotion;
          if (person.expressions.happy > 0.5) {
            emotion = "Smile";
          } else if (person.expressions.neutral > 0.5) {
            emotion = "Neutral";
          } else {
            emotion = "Sad";
          }
          // Draw emotional state text
          ctx.font = 'bold 20px "Segoe UI"'; // Adjust the font size and style
          ctx.fillText(emotion, 150, canvas.height - 35); // Adjust the position of the text
        }
      }

      let smileStartTime; // Variable to store the time when the smile is detected
      let smileDetected = false; // Flag to track if a smile is detected
      let smileTime = 0; // Variable to store the smile time

      // Add event listener for canvas click
      canvas.addEventListener("click", function (event) {
        console.log("Canvas clicked");
        const ctx = canvas.getContext("2d", { willReadFrequently: true });
        if (!ctx) return;
        const rect = canvas.getBoundingClientRect();
        const clickX = event.clientX - rect.left;
        const clickY = event.clientY - rect.top;
        const overlayX = canvas.width - 440; // X coordinate of the overlay rectangle
        const overlayY = 10; // Y coordinate of the overlay rectangle
        const clickHereX = overlayX + 280; // X coordinate of the "Click Here" text
        const clickHereY = overlayY + 40; // Y coordinate of the "Click Here" text

        // Check if click is within "Click Here" text boundaries
        if (
          clickX >= clickHereX &&
          clickX <= clickHereX + ctx.measureText("Click Here").width &&
          clickY >= clickHereY - 20 &&
          clickY <= clickHereY + 10
        ) {
          window.location.href = "index.html"; // Navigate to index.html
        }
      });

      async function detectVideo(video, canvas) {
        if (!video || video.paused) return false;
        const t0 = performance.now();
        faceapi
          .detectAllFaces(video, optionsSSDMobileNet)
          .withFaceLandmarks()
          .withFaceExpressions()
          .withAgeAndGender()
          .then((result) => {
            const fps = 1000 / (performance.now() - t0);
            drawFaces(canvas, result, fps, smileTime);
            // Check if any face is detected and if smiling
            if (result.length > 0 && result[0].expressions.happy > 0.5) {
              if (!smileDetected) {
                // Start timer if smile is newly detected
                smileStartTime = performance.now();
                smileDetected = true;
              }
              // Update smile time every frame
              smileTime = Math.round(
                (performance.now() - smileStartTime) / 1000
              );
              if (smileTime === 5) {
                window.location.href = "index.html";
              }
            } else {
              // Reset smile time if no smile detected
              smileDetected = false;
              smileTime = 0;
            }
            requestAnimationFrame(() => detectVideo(video, canvas));
            return true;
          })
          .catch((err) => {
            log(`Detect Error: ${str(err)}`);
            return false;
          });
        return false;
      }

      // just initialize everything and call main function
      async function setupCamera() {
        const video = document.getElementById("video");
        const canvas = document.getElementById("canvas");
        if (!video || !canvas) return null;

        log("Setting up camera");
        // setup webcam. note that navigator.mediaDevices requires that page is accessed via https
        if (!navigator.mediaDevices) {
          log("Camera Error: access not supported");
          return null;
        }
        let stream;
        const constraints = {
          audio: false,
          video: { facingMode: "user", resizeMode: "crop-and-scale" },
        };
        if (window.innerWidth > window.innerHeight)
          constraints.video.width = { ideal: window.innerWidth };
        else constraints.video.height = { ideal: window.innerHeight };
        try {
          stream = await navigator.mediaDevices.getUserMedia(constraints);
        } catch (err) {
          if (
            err.name === "PermissionDeniedError" ||
            err.name === "NotAllowedError"
          )
            log(
              `Camera Error: camera permission denied: ${err.message || err}`
            );
          if (err.name === "SourceUnavailableError")
            log(`Camera Error: camera not available: ${err.message || err}`);
          return null;
        }
        if (stream) {
          video.srcObject = stream;
        } else {
          log("Camera Error: stream empty");
          return null;
        }
        const track = stream.getVideoTracks()[0];
        const settings = track.getSettings();
        if (settings.deviceId) delete settings.deviceId;
        if (settings.groupId) delete settings.groupId;
        if (settings.aspectRatio)
          settings.aspectRatio = Math.trunc(100 * settings.aspectRatio) / 100;
        log(`Camera active: ${track.label}`);
        log(`Camera settings: ${str(settings)}`);
        return new Promise((resolve) => {
          video.onloadeddata = async () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            video.play();
            detectVideo(video, canvas);
            resolve(true);
          };
        });
      }

      async function setupFaceAPI() {
        await faceapi.nets.ssdMobilenetv1.load(modelPath);
        await faceapi.nets.ageGenderNet.load(modelPath);
        await faceapi.nets.faceLandmark68Net.load(modelPath);
        await faceapi.nets.faceRecognitionNet.load(modelPath);
        await faceapi.nets.faceExpressionNet.load(modelPath);
        optionsSSDMobileNet = new faceapi.SsdMobilenetv1Options({
          minConfidence: minScore,
          maxResults,
        });
      }

      async function main() {
        // default is webgl backend
        await faceapi.tf.setBackend("webgl");
        await faceapi.tf.ready();

        // tfjs optimizations
        if (faceapi.tf?.env().flagRegistry.CANVAS2D_WILL_READ_FREQUENTLY)
          faceapi.tf.env().set("CANVAS2D_WILL_READ_FREQUENTLY", true);
        if (faceapi.tf?.env().flagRegistry.WEBGL_EXP_CONV)
          faceapi.tf.env().set("WEBGL_EXP_CONV", true);
        if (faceapi.tf?.env().flagRegistry.WEBGL_EXP_CONV)
          faceapi.tf.env().set("WEBGL_EXP_CONV", true);
        await setupFaceAPI();
        await setupCamera();
      }

      // start processing as soon as page is loaded
      window.onload = main;
    </script>
  </head>
  <body
    style="
      font-family: monospace;
      background: black;
      color: white;
      font-size: 16px;
      line-height: 22px;
      margin: 0;
      overflow: hidden;
    "
  >
    <video id="video" playsinline class="video"></video>
    <canvas
      id="canvas"
      class="canvas"
      style="position: fixed; top: 0; left: 0; z-index: 3"
    ></canvas>
    <div id="log" style="overflow-y: scroll; height: 16.5rem"></div>
  </body>
</html>
